"""
Reverse Testing - åå‘æµ‹è¯•ä¸é²æ£’æ€§éªŒè¯

èŒè´£ï¼š
1. æ‰§è¡Œå…¨é¢çš„åå‘æµ‹è¯•ï¼ˆå¤±è´¥åœºæ™¯ã€è¾¹ç•Œæ¡ä»¶ï¼‰
2. æ€§èƒ½å›å½’æ£€æµ‹
3. è¾¹ç¼˜æƒ…å†µè¦†ç›–
4. æ··æ²Œæµ‹è¯•ï¼ˆéšæœºè¾“å…¥ã€é”™è¯¯æ³¨å…¥ï¼‰

åŸºäº Gemini Pro 3 çš„å»ºè®®ï¼š
- ä¼˜åŒ–"å¤±è´¥æ¨¡å¼é¢„é˜²"é€»è¾‘
- å¢å¼ºåå‘æµ‹è¯•è¦†ç›–èŒƒå›´
- ä¸»åŠ¨å‘ç°æ½œåœ¨é—®é¢˜
"""

import os
import json
import asyncio
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from datetime import datetime


class ReverseTestCase:
    """åå‘æµ‹è¯•ç”¨ä¾‹å®šä¹‰"""

    def __init__(self, test_id: str, metadata: Dict):
        self.test_id = test_id
        self.name = metadata.get("name", test_id)
        self.category = metadata.get("category", "general")
        self.description = metadata.get("description", "")
        self.test_type = metadata.get("test_type", "functional")  # functional, performance, security
        self.scenario = metadata.get("scenario", {})
        self.expected_behavior = metadata.get("expected_behavior", {})
        self.severity = metadata.get("severity", "medium")  # low, medium, high, critical


class ReverseTestSuite:
    """åå‘æµ‹è¯•å¥—ä»¶"""

    def __init__(self, project_path: str):
        """
        åˆå§‹åŒ–åå‘æµ‹è¯•å¥—ä»¶

        Args:
            project_path: é¡¹ç›®è·¯å¾„
        """
        self.project_path = Path(project_path).absolute()
        self.test_cases: List[ReverseTestCase] = []
        self._load_test_cases()

    def _load_test_cases(self):
        """åŠ è½½åå‘æµ‹è¯•ç”¨ä¾‹"""
        # æ ¹æ®é¡¹ç›®ç±»å‹ç”Ÿæˆé»˜è®¤æµ‹è¯•ç”¨ä¾‹
        self._generate_default_test_cases()

    def _generate_default_test_cases(self):
        """ç”Ÿæˆé»˜è®¤åå‘æµ‹è¯•ç”¨ä¾‹"""

        # æµ‹è¯•ç”¨ä¾‹ 1: ç©ºè¾“å…¥å¤„ç†
        self.test_cases.append(ReverseTestCase(
            "empty-input-001",
            {
                "name": "ç©ºè¾“å…¥å¤„ç†",
                "category": "input_validation",
                "test_type": "functional",
                "description": "ç³»ç»Ÿåº”ä¼˜é›…åœ°å¤„ç†ç©ºè¾“å…¥ï¼Œä¸åº”å´©æºƒæˆ–è¿”å›é”™è¯¯ä¿¡æ¯",
                "scenario": {
                    "input": "",
                    "input_type": "string",
                    "context": "æ‰€æœ‰è¡¨å•è¾“å…¥ã€API ç«¯ç‚¹"
                },
                "expected_behavior": {
                    "should_crash": False,
                    "should_validate": True,
                    "error_message": "å‹å¥½çš„é”™è¯¯æç¤º",
                    "fallback": "ä½¿ç”¨é»˜è®¤å€¼æˆ–æç¤ºç”¨æˆ·è¾“å…¥"
                },
                "severity": "high"
            }
        ))

        # æµ‹è¯•ç”¨ä¾‹ 2: è¶…é•¿è¾“å…¥å¤„ç†
        self.test_cases.append(ReverseTestCase(
            "long-input-001",
            {
                "name": "è¶…é•¿è¾“å…¥å¤„ç†",
                "category": "input_validation",
                "test_type": "functional",
                "description": "ç³»ç»Ÿåº”å¤„ç†è¶…é•¿è¾“å…¥ï¼ˆ10000+ å­—ç¬¦ï¼‰ï¼Œä¸åº”å¯¼è‡´å†…å­˜æº¢å‡ºæˆ–æ€§èƒ½ä¸‹é™",
                "scenario": {
                    "input": "A" * 10000,
                    "input_type": "string",
                    "context": "æ–‡æœ¬è¾“å…¥æ¡†ã€textareaã€API è¯·æ±‚ä½“"
                },
                "expected_behavior": {
                    "should_crash": False,
                    "should_truncate": True,
                    "max_length": 1000,
                    "error_message": "è¾“å…¥è¶…è¿‡æœ€å¤§é•¿åº¦é™åˆ¶"
                },
                "severity": "medium"
            }
        ))

        # æµ‹è¯•ç”¨ä¾‹ 3: ç‰¹æ®Šå­—ç¬¦æ³¨å…¥
        self.test_cases.append(ReverseTestCase(
            "special-chars-001",
            {
                "name": "ç‰¹æ®Šå­—ç¬¦æ³¨å…¥",
                "category": "security",
                "test_type": "security",
                "description": "ç³»ç»Ÿåº”å®‰å…¨å¤„ç†ç‰¹æ®Šå­—ç¬¦ï¼Œé˜²æ­¢ XSSã€SQL æ³¨å…¥ç­‰æ”»å‡»",
                "scenario": {
                    "inputs": [
                        "<script>alert('XSS')</script>",
                        "'; DROP TABLE users; --",
                        "../../../etc/passwd",
                        "${7*7}",  # æ¨¡æ¿æ³¨å…¥
                        "{{7*7}}"  # æ¨¡æ¿æ³¨å…¥
                    ],
                    "context": "æ‰€æœ‰ç”¨æˆ·è¾“å…¥ç‚¹"
                },
                "expected_behavior": {
                    "should_execute": False,
                    "should_sanitize": True,
                    "should_escape": True,
                    "error_message": "åŒ…å«éæ³•å­—ç¬¦"
                },
                "severity": "critical"
            }
        ))

        # æµ‹è¯•ç”¨ä¾‹ 4: API è¶…æ—¶å¤„ç†
        self.test_cases.append(ReverseTestCase(
            "api-timeout-001",
            {
                "name": "API è¶…æ—¶å¤„ç†",
                "category": "resilience",
                "test_type": "functional",
                "description": "å¤–éƒ¨ API è°ƒç”¨è¶…æ—¶æ—¶ï¼Œç³»ç»Ÿåº”ä¼˜é›…é™çº§ï¼Œä¸åº”æŒ‚èµ·",
                "scenario": {
                    "api_call": "å¤–éƒ¨ LLM API",
                    "timeout": 30,
                    "simulate": "å»¶è¿Ÿå“åº”æˆ–æ— å“åº”"
                },
                "expected_behavior": {
                    "should_hang": False,
                    "should_retry": True,
                    "max_retries": 3,
                    "fallback": "ä½¿ç”¨æ™ºèƒ½è§„åˆ™ç³»ç»Ÿ",
                    "error_message": "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
                },
                "severity": "high"
            }
        ))

        # æµ‹è¯•ç”¨ä¾‹ 5: å¹¶å‘è¯·æ±‚å¤„ç†
        self.test_cases.append(ReverseTestCase(
            "concurrent-requests-001",
            {
                "name": "å¹¶å‘è¯·æ±‚å¤„ç†",
                "category": "performance",
                "test_type": "performance",
                "description": "ç³»ç»Ÿåº”æ­£ç¡®å¤„ç†å¹¶å‘è¯·æ±‚ï¼Œä¸åº”å‡ºç°ç«æ€æ¡ä»¶æˆ–æ•°æ®ä¸ä¸€è‡´",
                "scenario": {
                    "concurrent_users": 100,
                    "requests_per_second": 50,
                    "duration": "10ç§’"
                },
                "expected_behavior": {
                    "should_crash": False,
                    "should_handle": True,
                    "response_time": "< 500ms (P95)",
                    "error_rate": "< 1%"
                },
                "severity": "medium"
            }
        ))

        # æµ‹è¯•ç”¨ä¾‹ 6: æ— æ•ˆ JSON å¤„ç†
        self.test_cases.append(ReverseTestCase(
            "invalid-json-001",
            {
                "name": "æ— æ•ˆ JSON å¤„ç†",
                "category": "input_validation",
                "test_type": "functional",
                "description": "API åº”æ­£ç¡®å¤„ç†æ— æ•ˆ JSON è¯·æ±‚ï¼Œä¸åº”å´©æºƒ",
                "scenario": {
                    "content_type": "application/json",
                    "body": "{invalid json",
                    "endpoint": "POST /api/*"
                },
                "expected_behavior": {
                    "should_crash": False,
                    "status_code": 400,
                    "error_message": "Invalid JSON format"
                },
                "severity": "medium"
            }
        ))

        # æµ‹è¯•ç”¨ä¾‹ 7: æ•°æ®åº“è¿æ¥å¤±è´¥
        self.test_cases.append(ReverseTestCase(
            "db-failure-001",
            {
                "name": "æ•°æ®åº“è¿æ¥å¤±è´¥",
                "category": "resilience",
                "test_type": "functional",
                "description": "æ•°æ®åº“ä¸å¯ç”¨æ—¶ï¼Œç³»ç»Ÿåº”ä¼˜é›…é™çº§ï¼Œä¸åº”æš´éœ²æ•æ„Ÿé”™è¯¯ä¿¡æ¯",
                "scenario": {
                    "failure_type": "connection_refused",
                    "simulate": "åœæ­¢æ•°æ®åº“æœåŠ¡"
                },
                "expected_behavior": {
                    "should_crash": False,
                    "should_retry": True,
                    "fallback": "ä½¿ç”¨ç¼“å­˜æˆ–è¿”å›å‹å¥½é”™è¯¯",
                    "error_message": "æœåŠ¡æš‚æ—¶ä¸å¯ç”¨",
                    "should_log": True  # è®°å½•è¯¦ç»†é”™è¯¯åˆ°æ—¥å¿—
                },
                "severity": "critical"
            }
        ))

        # æµ‹è¯•ç”¨ä¾‹ 8: å†…å­˜æ³„æ¼æ£€æµ‹
        self.test_cases.append(ReverseTestCase(
            "memory-leak-001",
            {
                "name": "å†…å­˜æ³„æ¼æ£€æµ‹",
                "category": "performance",
                "test_type": "performance",
                "description": "é•¿æ—¶é—´è¿è¡Œä¸åº”å¯¼è‡´å†…å­˜æŒç»­å¢é•¿",
                "scenario": {
                    "operations": [
                        "åˆ›å»ºå’Œé”€æ¯ç»„ä»¶",
                        "é¢‘ç¹ API è°ƒç”¨",
                        "æ–‡ä»¶è¯»å†™"
                    ],
                    "iterations": 1000,
                    "duration": "5åˆ†é’Ÿ"
                },
                "expected_behavior": {
                    "memory_growth": "< 20%",
                    "should_release": True,
                    "gc_effective": True
                },
                "severity": "medium"
            }
        ))

        # æµ‹è¯•ç”¨ä¾‹ 9: ç½‘ç»œæ–­å¼€æ¢å¤
        self.test_cases.append(ReverseTestCase(
            "network-recovery-001",
            {
                "name": "ç½‘ç»œæ–­å¼€æ¢å¤",
                "category": "resilience",
                "test_type": "functional",
                "description": "ç½‘ç»œæ–­å¼€åæ¢å¤ï¼Œç³»ç»Ÿåº”è‡ªåŠ¨é‡è¿å¹¶æ¢å¤çŠ¶æ€",
                "scenario": {
                    "events": [
                        "æ­£å¸¸æ“ä½œ",
                        "ç½‘ç»œæ–­å¼€",
                        "ç­‰å¾… 10 ç§’",
                        "ç½‘ç»œæ¢å¤",
                        "éªŒè¯çŠ¶æ€"
                    ]
                },
                "expected_behavior": {
                    "should_detect": True,
                    "should_retry": True,
                    "should_restore": True,
                    "user_prompt": "ç½‘ç»œå·²æ–­å¼€ï¼Œæ­£åœ¨é‡è¿..."
                },
                "severity": "high"
            }
        ))

        # æµ‹è¯•ç”¨ä¾‹ 10: è¾¹ç•Œå€¼æµ‹è¯•
        self.test_cases.append(ReverseTestCase(
            "boundary-values-001",
            {
                "name": "è¾¹ç•Œå€¼æµ‹è¯•",
                "category": "input_validation",
                "test_type": "functional",
                "description": "æµ‹è¯•æ•°å€¼è¾¹ç•Œï¼ˆ0ã€-1ã€æœ€å¤§å€¼ã€æœ€å°å€¼ï¼‰",
                "scenario": {
                    "inputs": [
                        {"value": 0, "description": "é›¶å€¼"},
                        {"value": -1, "description": "è´Ÿæ•°"},
                        {"value": 2147483647, "description": "INT_MAX"},
                        {"value": -2147483648, "description": "INT_MIN"},
                        {"value": 3.14159265359, "description": "æµ®ç‚¹æ•°ç²¾åº¦"}
                    ],
                    "context": "æ‰€æœ‰æ•°å€¼è¾“å…¥"
                },
                "expected_behavior": {
                    "should_validate": True,
                    "should_handle": True,
                    "error_message": "æ•°å€¼è¶…å‡ºå…è®¸èŒƒå›´"
                },
                "severity": "medium"
            }
        ))

        print(f"  ğŸ§ª Loaded {len(self.test_cases)} reverse test cases")

    async def run_reverse_tests(
        self,
        feature: Dict,
        test_categories: Optional[List[str]] = None
    ) -> Dict:
        """
        è¿è¡Œåå‘æµ‹è¯•

        Args:
            feature: åŠŸèƒ½å®šä¹‰
            test_categories: æµ‹è¯•ç±»åˆ«ï¼ˆå¯é€‰ï¼Œå¦‚ ['input_validation', 'security']ï¼‰

        Returns:
            æµ‹è¯•ç»“æœ
        """
        print(f"  ğŸ§ª [Reverse Testing] Running reverse tests...")

        # æ ¹æ®åŠŸèƒ½é€‰æ‹©ç›¸å…³æµ‹è¯•ç”¨ä¾‹
        relevant_tests = self._filter_tests_by_feature(feature, test_categories)

        if not relevant_tests:
            print(f"  â„¹ï¸  No relevant reverse tests found for feature {feature['id']}")
            return {
                "passed": True,
                "tests_run": 0,
                "message": "No applicable reverse tests"
            }

        results = []
        critical_failures = []

        for test_case in relevant_tests:
            print(f"    â†’ Running: {test_case.name}")
            result = await self._run_single_test(test_case, feature)
            results.append(result)

            if not result["passed"] and test_case.severity == "critical":
                critical_failures.append({
                    "test_id": test_case.test_id,
                    "name": test_case.name,
                    "issue": result.get("issue", "Unknown")
                })

        # æ±‡æ€»ç»“æœ
        total_tests = len(results)
        passed_tests = sum(1 for r in results if r["passed"])
        failed_tests = total_tests - passed_tests

        all_passed = len(critical_failures) == 0

        if all_passed:
            print(f"  âœ… [Reverse Testing] All tests passed ({passed_tests}/{total_tests})")
        else:
            print(f"  âŒ [Reverse Testing] {failed_tests} tests failed, {len(critical_failures)} critical")

        return {
            "passed": all_passed,
            "tests_run": total_tests,
            "passed_tests": passed_tests,
            "failed_tests": failed_tests,
            "results": results,
            "critical_failures": critical_failures
        }

    def _filter_tests_by_feature(
        self,
        feature: Dict,
        categories: Optional[List[str]]
    ) -> List[ReverseTestCase]:
        """
        æ ¹æ®åŠŸèƒ½ç­›é€‰ç›¸å…³æµ‹è¯•ç”¨ä¾‹

        Args:
            feature: åŠŸèƒ½å®šä¹‰
            categories: æµ‹è¯•ç±»åˆ«ï¼ˆå¯é€‰ï¼‰

        Returns:
            ç›¸å…³æµ‹è¯•ç”¨ä¾‹åˆ—è¡¨
        """
        filtered = self.test_cases

        # æŒ‰ç±»åˆ«ç­›é€‰
        if categories:
            filtered = [t for t in filtered if t.category in categories]

        # æŒ‰åŠŸèƒ½ç±»åˆ«æ™ºèƒ½ç­›é€‰
        feature_category = feature.get("category", "")
        feature_desc = feature.get("description", "").lower()

        # å¦‚æœæ˜¯ API ç›¸å…³åŠŸèƒ½ï¼Œè·³è¿‡çº¯ UI æµ‹è¯•
        if feature_category in ["api", "backend"]:
            filtered = [t for t in filtered if t.category not in ["ui_only"]]

        # å¦‚æœåŠŸèƒ½æè¿°ä¸­æåˆ°"å®‰å…¨"ã€"è®¤è¯"ï¼Œå¢åŠ å®‰å…¨æµ‹è¯•
        if any(keyword in feature_desc for keyword in ["auth", "login", "password", "security"]):
            security_tests = [t for t in self.test_cases if t.category == "security"]
            filtered.extend(security_tests)

        # å»é‡
        seen = set()
        unique_filtered = []
        for test in filtered:
            if test.test_id not in seen:
                seen.add(test.test_id)
                unique_filtered.append(test)

        return unique_filtered

    async def _run_single_test(
        self,
        test_case: ReverseTestCase,
        feature: Dict
    ) -> Dict:
        """
        è¿è¡Œå•ä¸ªæµ‹è¯•ç”¨ä¾‹

        Args:
            test_case: æµ‹è¯•ç”¨ä¾‹
            feature: åŠŸèƒ½å®šä¹‰

        Returns:
            æµ‹è¯•ç»“æœ
        """
        try:
            # æ ¹æ®æµ‹è¯•ç±»å‹æ‰§è¡Œä¸åŒçš„æµ‹è¯•é€»è¾‘
            if test_case.test_type == "functional":
                return await self._run_functional_test(test_case, feature)
            elif test_case.test_type == "performance":
                return await self._run_performance_test(test_case, feature)
            elif test_case.test_type == "security":
                return await self._run_security_test(test_case, feature)
            else:
                return {
                    "test_id": test_case.test_id,
                    "passed": True,
                    "skipped": True,
                    "reason": "Unknown test type"
                }

        except Exception as e:
            return {
                "test_id": test_case.test_id,
                "passed": False,
                "error": str(e),
                "issue": f"Test execution failed: {e}"
            }

    async def _run_functional_test(
        self,
        test_case: ReverseTestCase,
        feature: Dict
    ) -> Dict:
        """è¿è¡ŒåŠŸèƒ½æµ‹è¯•"""
        # è¿™é‡Œå®ç°å®é™…çš„åŠŸèƒ½æµ‹è¯•é€»è¾‘
        # ä¾‹å¦‚ï¼šå‘é€æµ‹è¯•è¯·æ±‚ã€æ£€æŸ¥å“åº”ã€éªŒè¯è¡Œä¸º

        # ç®€åŒ–å®ç°ï¼šåŸºäºè§„åˆ™æ£€æŸ¥
        passed = self._check_functional_requirements(test_case, feature)

        return {
            "test_id": test_case.test_id,
            "passed": passed,
            "test_type": "functional",
            "severity": test_case.severity,
            "issue": None if passed else f"Functional requirement not met: {test_case.name}"
        }

    async def _run_performance_test(
        self,
        test_case: ReverseTestCase,
        feature: Dict
    ) -> Dict:
        """è¿è¡Œæ€§èƒ½æµ‹è¯•"""
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥ä»£ç ä¸­æ˜¯å¦æœ‰æ€§èƒ½ä¼˜åŒ–æªæ–½
        passed = self._check_performance_requirements(test_case, feature)

        return {
            "test_id": test_case.test_id,
            "passed": passed,
            "test_type": "performance",
            "severity": test_case.severity,
            "issue": None if passed else f"Performance requirement not met: {test_case.name}"
        }

    async def _run_security_test(
        self,
        test_case: ReverseTestCase,
        feature: Dict
    ) -> Dict:
        """è¿è¡Œå®‰å…¨æµ‹è¯•"""
        # ç®€åŒ–å®ç°ï¼šæ£€æŸ¥ä»£ç ä¸­æ˜¯å¦æœ‰å®‰å…¨é˜²æŠ¤æªæ–½
        passed = self._check_security_requirements(test_case, feature)

        return {
            "test_id": test_case.test_id,
            "passed": passed,
            "test_type": "security",
            "severity": test_case.severity,
            "issue": None if passed else f"Security requirement not met: {test_case.name}"
        }

    def _check_functional_requirements(
        self,
        test_case: ReverseTestCase,
        feature: Dict
    ) -> bool:
        """æ£€æŸ¥åŠŸèƒ½éœ€æ±‚ï¼ˆåŸºäºè§„åˆ™ï¼‰"""
        # è¯»å–ç›¸å…³ä»£ç æ–‡ä»¶
        code_files = self._get_feature_code_files(feature)

        if not code_files:
            # å¦‚æœæ²¡æœ‰ä»£ç æ–‡ä»¶ï¼Œè·³è¿‡æµ‹è¯•
            return True

        all_code = "\n".join(code_files.values())

        # æ ¹æ®æµ‹è¯•ç”¨ä¾‹ç±»å‹æ£€æŸ¥
        if test_case.test_id == "empty-input-001":
            # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥éªŒè¯
            has_validation = (
                "required" in all_code.lower() or
                "validator" in all_code.lower() or
                "if not" in all_code or
                "if ==" in all_code
            )
            return has_validation

        elif test_case.test_id == "api-timeout-001":
            # æ£€æŸ¥æ˜¯å¦æœ‰è¶…æ—¶å¤„ç†
            has_timeout = (
                "timeout" in all_code.lower() or
                "retry" in all_code.lower() or
                "except" in all_code
            )
            return has_timeout

        elif test_case.test_id == "invalid-json-001":
            # æ£€æŸ¥æ˜¯å¦æœ‰é”™è¯¯å¤„ç†
            has_error_handling = (
                "try {" in all_code or
                "try:" in all_code or
                "catch" in all_code.lower() or
                "except" in all_code
            )
            return has_error_handling

        # é»˜è®¤é€šè¿‡
        return True

    def _check_performance_requirements(
        self,
        test_case: ReverseTestCase,
        feature: Dict
    ) -> bool:
        """æ£€æŸ¥æ€§èƒ½éœ€æ±‚ï¼ˆåŸºäºè§„åˆ™ï¼‰"""
        code_files = self._get_feature_code_files(feature)

        if not code_files:
            return True

        all_code = "\n".join(code_files.values())

        if test_case.test_id == "memory-leak-001":
            # æ£€æŸ¥æ˜¯å¦æœ‰èµ„æºæ¸…ç†é€»è¾‘
            has_cleanup = (
                "cleanup" in all_code.lower() or
                "dispose" in all_code.lower() or
                "finally" in all_code.lower() or
                "close()" in all_code
            )
            return has_cleanup

        # é»˜è®¤é€šè¿‡
        return True

    def _check_security_requirements(
        self,
        test_case: ReverseTestCase,
        feature: Dict
    ) -> bool:
        """æ£€æŸ¥å®‰å…¨éœ€æ±‚ï¼ˆåŸºäºè§„åˆ™ï¼‰"""
        code_files = self._get_feature_code_files(feature)

        if not code_files:
            return True

        all_code = "\n".join(code_files.values())

        if test_case.test_id == "special-chars-001":
            # æ£€æŸ¥æ˜¯å¦æœ‰è¾“å…¥æ¸…ç†
            has_sanitization = (
                "sanitize" in all_code.lower() or
                "escape" in all_code.lower() or
                "validate" in all_code.lower() or
                "filter" in all_code.lower()
            )
            return has_sanitization

        # é»˜è®¤é€šè¿‡
        return True

    def _get_feature_code_files(self, feature: Dict) -> Dict[str, str]:
        """è·å–åŠŸèƒ½ç›¸å…³çš„ä»£ç æ–‡ä»¶"""
        code_files = {}

        # æ ¹æ®åŠŸèƒ½ç±»åˆ«æŸ¥æ‰¾æ–‡ä»¶
        category = feature.get("category", "")

        if category in ["ui", "frontend"]:
            for ts_file in self.project_path.rglob("*.tsx"):
                code_files[str(ts_file.relative_to(self.project_path))] = ts_file.read_text()

        elif category in ["api", "backend"]:
            for py_file in self.project_path.rglob("*.py"):
                code_files[str(py_file.relative_to(self.project_path))] = py_file.read_text()

        return code_files


# å…¨å±€å‡½æ•°
async def run_reverse_tests_for_feature(
    project_path: str,
    feature: Dict,
    test_categories: Optional[List[str]] = None
) -> Dict:
    """
    ä¸ºåŠŸèƒ½è¿è¡Œåå‘æµ‹è¯•çš„ä¾¿æ·å‡½æ•°

    Args:
        project_path: é¡¹ç›®è·¯å¾„
        feature: åŠŸèƒ½å®šä¹‰
        test_categories: æµ‹è¯•ç±»åˆ«ï¼ˆå¯é€‰ï¼‰

    Returns:
        æµ‹è¯•ç»“æœ
    """
    suite = ReverseTestSuite(project_path)
    return await suite.run_reverse_tests(feature, test_categories)
